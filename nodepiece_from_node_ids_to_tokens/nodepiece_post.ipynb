{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explosion of interest and progress in natural language processing (NLP) and large language models (LLMs) is well-documented, with terms like “tokenization” and “transformers” can be seen everywhere. Yet, the equally potent realm of graph neural networks (GNNs) and specifically knowledge graph embeddings remains much less popular, outside specialized circles. These technologies offer powerful solutions across various applications, from recommendation systems to link prediction and node classification.\n",
    "\n",
    "One of the techniques in the GNN world that, in my opinion, requires much more attention is NodePiece tokenization: a novel approach that imports several concepts from NLP to enhance the functionality of graph neural networks. This technique employs a finite set of universal “tokens” to represent nodes within a graph. This approach eliminates the need for a predefined vocabulary of IDs, allowing for a more adaptable representation of nodes and improving the model's ability to generalize across different graphs.\n",
    "\n",
    "Despite its potential, the NodePiece tokenization methodology is not as widely discussed as e.g., LLMs. This blog post seeks to demystify NodePiece tokenization, offering a clear, intuitive explanation and a practical Python implementation for hands-on learning, as the existing implementations are quite complex and built-into pre-existing libraries.\n",
    "\n",
    "By the end of this post, you will:\n",
    "\n",
    "1. Grasp the fundamental concepts of NodePiece tokenization.\n",
    "2. Comprehend the rationale and principles underpinning this technique.\n",
    "3. Gain the skills to implement a basic version of NodePiece tokenization in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook accompanying the blogpost about the NodePiece graph algorithm. You can read this notebook as a standalone post, or just refer to the code fragments mentioned in the text.\n",
    "\n",
    "For clarity, longer modules (like neural network itself, or the training loop) are stored in separate modules, in the same directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set variable for CUDA determinism\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.data as pyg_data\n",
    "import torch_geometric.datasets as pyg_datasets\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import pytorch_lightning as pl\n",
    "import torcheval.metrics.functional as tmf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import random\n",
    "import inspect\n",
    "\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Tuple\n",
    "from networkx import Graph\n",
    "\n",
    "import models as models\n",
    "import tokenization as tok\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: The magic of building blocks\n",
    "\n",
    "## The NLP world - history\n",
    "\n",
    "Reflecting on the evolution of NLP, early stages were dominated by methodologies like word embeddings, lemmatization, and tokenization. Pioneering algorithms such as Word2Vec **(Church, 2017)** and GloVe **(Brochier et al., 2019)** set the standard, operating under a relatively straightforward process:\n",
    "\n",
    "1. Compile a large corpus of text.\n",
    "\n",
    "2. Preprocess it through tokenization, lemmatization, and similar techniques.\n",
    "\n",
    "3. Construct embedding lookups that map the processed words to unique IDs.\n",
    "\n",
    "This approach, however, required the allocation of massive embedding matrices, which were both space-consuming and computationally expensive.\n",
    "\n",
    "For instance, consider an embedding matrix defined as:\n",
    "\n",
    "$$\\text{Emb matrix} \\in \\mathbb{R}^{V \\times E}$$\n",
    "\n",
    "Where V was the size of the vocabulary, and E was the size of the embedding. A vocabulary of **100,000 words** with an embedding size of **300** would require the allocation of **30 million floats**, a significant demand on resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The advent of transformer tokenizers\n",
    "\n",
    "The introduction of transformers and their associated tokenization methods revolutionized the field. Techniques like Byte-Pair Encoding (BPE) **(Sennrich et al., 2016)** introduced the concept of sub-words, akin to building blocks or alphabets, significantly streamlining the tokenization process. These sub-words or tokens are not only more compact than whole words but also universal, enabling their application across various languages and the seamless introduction of new vocabulary.\n",
    "Consider the sentence: \n",
    "\n",
    "> “Modern tokenizers revolutionized the way we process text these days.”\n",
    "\n",
    "\n",
    "Traditional methods would tokenize this into separate words and assign each an embedding. However, a modern tokenizer might segment it into sub-words, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filip/miniconda3/envs/ds/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "modern\n",
      "token\n",
      "##izer\n",
      "##s\n",
      "revolution\n",
      "##ized\n",
      "the\n",
      "way\n",
      ",\n",
      "how\n",
      "we\n",
      "process\n",
      "text\n",
      "these\n",
      "days\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "for tok in tokenizer.encode(\"Modern tokenizers revolutionized the way, how we process text these days\").tokens:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the word \"tokenizers\" is split into \"token\" and \"##izers\", \"revolutionized\" into \"revolution\" and \"##ized\", and so forth. \n",
    "\n",
    "This removes the need for unique IDs for each new word like \"tokenizer\", as \"token\" and \"##izers\" are already in the vocabulary, enabling the construction of other words' representations while conserving embedding memory space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The world of graphs\n",
    "\n",
    "In the realm of graph processing and knowledge graph inference, the adoption of concepts analogous to those used in modern NLP tokenization has been slow to materialize. Traditional algorithms for knowledge graph reasoning, such as TransE **(Bordes et al., 2013)** and RotatE **(Sun et al., 2019)**, have predominantly relied on mapping entities and relations to unique embeddings. This approach, while straightforward, is markedly memory-intensive, each entity and relation requiring its unique identifier within the embedding space - just like words in the word2vec or older NLP solutions!.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> For those interested in learning more about TransE, RotatE, and similar models, I highly recommend a post on Medium.com <a href=\"https://medium.com/stanford-cs224w/simple-schemes-for-knowledge-graph-embedding-dd07c61f3267\">Simple Schemes for Knowledge Graph Embedding by Preston Carlson</a>. This article provides a comprehensive overview of the principles behind these models.\n",
    "</div>\n",
    "\n",
    "The search for scalable and effective solutions within the graph domain has been protracted, yet fruitful. **NodePiece** emerges as a one of the pioneering algorithms in this context, **drawing significant inspiration from the advancements in NLP tokenization**. By **applying the principles of modern tokenization techniques to graph structures, NodePiece offers a novel approach to representing graph entities and relationships**, marking a significant leap towards more memory-efficient and generalizable models in the knowledge graph domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: The NodePiece algorithm\n",
    "\n",
    "## Contributors and sources\n",
    "\n",
    "The NodePiece algorithm represents a significant advancement in the domain of knowledge graph embeddings, focusing on compositional and parameter-efficient representations of large knowledge graphs. Introduced in the paper **\"NodePiece: Compositional and parameter-efficient representations of large knowledge graphs\" (Galkin et al., 2021)**, this approach has been integrated into the **widely utilized Python library, PyKeen**.\n",
    "\n",
    "<a href=\"https://arxiv.org/pdf/2106.12144.pdf\">Galkin, M., Denis, E., Wu, J., & Hamilton, W. L. (2021). Nodepiece: Compositional and parameter-efficient representations of large knowledge graphs. arXiv preprint arXiv:2106.12144.</a>\n",
    "\n",
    "PyKeen implementation can be found <a href=\"https://pykeen.readthedocs.io/en/stable/\">here</a>.\n",
    "\n",
    "Additionally, the implementation authored by the paper's contributors is accessible on GitHub for those interested in exploring the codebase further.\n",
    "\n",
    ">  <a href=\"https://github.com/migalkin/NodePiece\">Github: Compositional and Parameter-Efficient Representations for Large Knowledge Graphs (ICLR'22) </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a comprehensive and accessible introduction to NodePiece from the theoretical point of view, I recommend reading the Medium blog post **\"NodePiece: Tokenizing Knowledge Graphs\" by Michael Galkin**, one of the co-authors of the original paper. This article offers an invaluable deep dive into the algorithm, providing insights directly from its developers.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NodePiece Blog Post:</b> The blog post <a href=\"https://towardsdatascience.com/nodepiece-tokenizing-knowledge-graphs-6dd2b91847aa\">NodePiece: Tokenizing Knowledge Graphs by Michael Galkin</a> stands out as a thorough explanation of the NodePiece algorithm, authored by one of its creators. This is an excellent resource for those seeking to understand the model beyond the original academic paper.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n",
    "The NodePiece algorithm is founded on a set of core assumptions that **shift away from the traditional requirement of assigning a unique identifier to each entity within a knowledge graph**. Instead, entities are depicted through a combination of basic building blocks, drawing parallels to the tokenization concepts in NLP. These building blocks comprise:\n",
    "\n",
    "1. **Positional Features**: The proximity of nodes to designated anchor nodes.\n",
    "2. **Relational Features**: The types of relationships in which the nodes are involve\n",
    "\n",
    "### Positional features\n",
    "\n",
    "Nodes are characterized **by their distances to a set of predetermined anchor nodes**. The method for selecting these anchor nodes varies, including options like **choosing the most connected nodes, employing clustering algorithms, or even random selection.**\n",
    "\n",
    "Regardless of the selection technique, the underlying principle remains straightforward — **each node is defined by its distance to the K nearest anchor nodes**. With a strategic choice of anchor nodes, there's a high likelihood that the proximity to the nearest anchors provides a unique “fingerprint” for each node.\n",
    "\n",
    "Consider the following example to illustrate this concept:\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    n1((node1)) --- n2((node2))\n",
    "    n1 --- n3\n",
    "    n2 --- n3\n",
    "    n2 --- a1(((Anchor 1)))\n",
    "    n3((node3)) --- n4((node4))\n",
    "    n4 --- a1\n",
    "    n4 --- n5((node5))\n",
    "    n5 --- a2(((Anchor 2)))\n",
    "    n2 --- a2\n",
    "    a1 --- a2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below summarizes distances of each node to anchors:\n",
    "\n",
    "\n",
    "| Node  | Anchor 1 | Anchor 2 |\n",
    "|-------|----------|----------|\n",
    "| node1 | 2        | 2        |\n",
    "| node2 | 1        | 1        |\n",
    "| node3 | 2        | 3        |\n",
    "| node4 | 1        | 2        |\n",
    "| node5 | 2        | 1        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational features\n",
    "\n",
    "In heterogeneous knowledge graphs, edges encapsulate diverse types of relationships between nodes. The NodePiece algorithm leverages these relationships as integral components of node representation, enriching the understanding of each node's context and connectivity within the graph. To illustrate how relational features are incorporated, let's revisit and expand upon our previous example, this time including relation types:\n",
    "\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    n1((node1)) -- r1 --- n2((node2))\n",
    "    n1 -- r2 --- n3\n",
    "    n2 -- r1 --- n3\n",
    "    n2 -- r3 --- a1(((Anchor 1)))\n",
    "    n3((node3)) -- r2 --- n4((node4))\n",
    "    n4 -- r1 --- a1\n",
    "    n4 -- r3 --- n5((node5))\n",
    "    n5 -- r2 --- a2(((Anchor 2)))\n",
    "    n2 -- r3 --- a2\n",
    "    a1 -- r1 --- a2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize the relations of each node in the following table:\n",
    "\n",
    "| Node  | relationships |\n",
    "|-------|---------------|\n",
    "| node1 | r1, r2            |\n",
    "| node2 | r1, r1, r3            |\n",
    "| node3 | r1, r2, r2            |\n",
    "| node4 | r1, r2, r3            |\n",
    "| node5 | r2, r3            |\n",
    "\n",
    "Or with couting each relation type:\n",
    "\n",
    "| Node  | r1 | r2 | r3 |\n",
    "|-------|----|----|----|\n",
    "| node1 | 1  | 1  | 0  |\n",
    "| node2 | 2  | 0  | 1  |\n",
    "| node3 | 1  | 2  | 0  |\n",
    "| node4 | 1  | 1  | 1  |\n",
    "| node5 | 0  | 1  | 1  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably you see now, where it is going..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The unique fingerprint - an intution\n",
    "\n",
    "The essence of the NodePiece algorithm lies in its ability to synthesize two distinct features—positional and relational—into a cohesive representation for each node. This amalgamation involves concatenating the proximity to the nearest anchor nodes with the types of relations a node engages in, thereby crafting a singular vector emblematic of the node's unique “fingerprint.”\n",
    "To conceptualize this process, consider representing node 2 through the following simplified schema\n",
    "\n",
    "```mermaid\n",
    "flowchart TB\n",
    "    a1(((Anchor 1))) --Distance=1--> ae[Anchor dist. vector]\n",
    "    a2(((Anchor 2))) --Distance=1--> ae[Anchor dist. vector]\n",
    "    r1 --> re[Relation context]\n",
    "    r3 --> re[Relation context]\n",
    "    re --Concatenate+embed--> Enc[\"Fingerprint\" vector]\n",
    "    ae --Concatenate+embed--> Enc[\"Fingerprint\" vector]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: A formal definition\n",
    "\n",
    "There are some important details to mention, before we start coding the NodePiece algorithm. For example:\n",
    "\n",
    "1. **Selective Anchor Usage**: Not every anchor is pertinent to each node's representation. Only the nearest k anchors are considered for embedding any given nod\n",
    "2. **Relational Sampling**: Similarly, a node's relational context is derived from sampling among its immediate outgoing relations, limited to *m* relations per node.\n",
    "3. **Handling Disconnections**: In instances where a node is disconnected or lacking links to any specified anchor or relation - a special `[DISCONNECTED]` token is employed, analogous to the `<OOV>` (out-of-vocabulary) token in NLP scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for some math.\n",
    "Let's start with whatis the input to NodePiece :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}\n",
       "\\text{Given: }& \\\\\n",
       "&KG = \\{N, E, R\\} \\text{, with } \\\\\n",
       "    &|N| \\text{ - number of nodes} \\\\\n",
       "    &|E| \\text{ - number of edges} \\\\\n",
       "    &|R| \\text{ - number of relations} \\\\\n",
       "    &A \\text{ - set of anchors selected from nodes} \\\\\n",
       "    &V = R + A \\text{- vocabulary for NodePiece: relations + anchors} \\\\\n",
       "    &k \\text{ - number of anchors to sample for each node} \\\\\n",
       "    &m \\text{ - number of immediate outgoing relations to sample from node} \\\\\n",
       "    &d \\text{ - vector size, that NodePiece will use to construct embeddings. Embedding size} \\\\\n",
       "     \\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align*}\n",
    "\\text{Given: }& \\\\\n",
    "&KG = \\{N, E, R\\} \\text{, with } \\\\\n",
    "    &|N| \\text{ - number of nodes} \\\\\n",
    "    &|E| \\text{ - number of edges} \\\\\n",
    "    &|R| \\text{ - number of relations} \\\\\n",
    "    &A \\text{ - set of anchors selected from nodes} \\\\\n",
    "    &V = R + A \\text{- vocabulary for NodePiece: relations + anchors} \\\\\n",
    "    &k \\text{ - number of anchors to sample for each node} \\\\\n",
    "    &m \\text{ - number of immediate outgoing relations to sample from node} \\\\\n",
    "    &d \\text{ - vector size, that NodePiece will use to construct embeddings. Embedding size} \\\\\n",
    "     \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that the NodePiece is designed to work with:\n",
    "1. **Knowledge graphs** - represented as a set of nodes (N) connected via some edges (E) that belong to particular relations (R).\n",
    "2. **Selected anchor nodes (A)** - they will be a part of each nodes' \"fingerprint\" represetnation.\n",
    "3. **Relations (R) and anchors (A) form a vocabulary (V) for the model**.\n",
    "4. As stated in the paper - there is no need to use **all anchors for every node**, therefore *k* anchors are sampled.\n",
    "5. The same applies to relations - only *m* relations are sampled for each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-based form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the foundational elements at our disposal, we can move on to a formal definition for the unique “fingerprint” of each node within the graph. This fingerprint is divided into three  components:\n",
    "\n",
    "1. **Anchor Set**: A selection of k anchors randomly selected from the set of all anchors (A).\n",
    "2. **Anchor Distances**: The shortest path distances (SPDs) to these k closest anchors, as determined for the node. Should an anchor be unreachable, its distance is denoted with a predefined \"magic value.\" (like -1 or other token).\n",
    "3. **Relational Context**: A subset of m direct outgoing relations sampled for the node, encapsulating its immediate relational environment.\n",
    "\n",
    "Expressed formally, the representation for each node u in the vertex set V can be described as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}\n",
       "\\text{For each node } u &\\in V: \\\\\n",
       "    & \\{a_u\\}^k = \\{a \\mid \\forall a \\in sample(A, k)\\} \\\\\n",
       "    & \\{z_u\\}^k =\\{SPD(u, a) \\mid a \\in \\{a_u\\}^k \\} \\\\\n",
       "    & \\{r_j\\}^m = \\{r \\mid r \\in sample(out(u), m)\\} \\\\[1em]\n",
       "    & hash(u) = \\big[\\{a_u\\}^k,  \\{z_u\\}^k, \\{r_j\\}^m\\big]\n",
       "\\tag{1}\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align*}\n",
    "\\text{For each node } u &\\in V: \\\\\n",
    "    & \\{a_u\\}^k = \\{a \\mid \\forall a \\in sample(A, k)\\} \\\\\n",
    "    & \\{z_u\\}^k =\\{SPD(u, a) \\mid a \\in \\{a_u\\}^k \\} \\\\\n",
    "    & \\{r_j\\}^m = \\{r \\mid r \\in sample(out(u), m)\\} \\\\[1em]\n",
    "    & hash(u) = \\big[\\{a_u\\}^k,  \\{z_u\\}^k, \\{r_j\\}^m\\big]\n",
    "\\tag{1}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of the original paper advocate for the application of positional encoding to distances, thereby mapping each distance to a vector of dimension *d*. This approach ensures the maintenance of the embedding's intended dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}\n",
       "f_z &= z_u \\rightarrow \\mathbb{R}^d \\\\\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align*}\n",
    "f_z &= z_u \\rightarrow \\mathbb{R}^d \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both the anchors and their corresponding distances, an embedding lookup strategy is proposed. This implies that each anchor id (e.g., anchor=0) is associated with a specific row in the embedding matrix (e.g., row 0 for anchor 0, row 1 for anchor 1, up to row k for the last anchor), and similarly for distances (e.g., distance = 1 corresponds to embedding 1, etc.). This method facilitates an efficient and meaningful encoding of both the positional and relational aspects of each node's unique signature within the graph. \n",
    "\n",
    "**Bear in mind, that the number of anchors and anchor distances is much smaller than the population of unique node IDs, used by traditional methods.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding of anchors, distances and relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation of sets delineated in equation (1) into a vectorial representation through embedding involves several key steps:\n",
    "\n",
    "1. Converting the anchors for a node, denoted as $\\{a_u\\}^k$ into a vector $\\mathbf{A} \\in \\mathbb{R}^{k\\times d}$ mbedding these anchor identifiers into a  *d*-dimensional space.\n",
    "2. Transforming the anchor distances, $\\{z_u\\}^k$ into a vector $\\mathbf{Z} \\in \\mathbb{R}^{k \\times d}$ where each distance is treated akin to an identifier within the embedding vector, effectively encoding the proximity to sampled anchors.\n",
    "3. Mapping the relational context, $\\{r_u\\}^m$ into a vector $\\mathbf{R} \\in \\mathbb{R}^{m \\times d}$ which reflects the identifiers of sampled relations relevant to the node.\n",
    "\n",
    "Expressed formally, the comprehensive node hash function can be represented as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}\n",
       "\\mathbf{hash}(u) &= \\big[\\mathbf{a_u}, \\mathbf{z}_u,  \\mathbf{r}_u \\big] \\tag{2} \\\\\n",
       "\\text{where: } \\\\\n",
       "\\mathbf{a_u} &\\in \\mathbb{R}^{k \\times d} \\text{ - k anchor ids sampled for node}\\\\\n",
       "\\mathbf{z_u} &\\in \\mathbb{R}^{k \\times d} \\text{ - k anchor distances }\\\\\n",
       "\\mathbf{r_u} &\\in \\mathbb{R}^{m \\times d} \\text{ - m outgoing relations} \\\\\n",
       "\\end{align*} \n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align*}\n",
    "\\mathbf{hash}(u) &= \\big[\\mathbf{a_u}, \\mathbf{z}_u,  \\mathbf{r}_u \\big] \\tag{2} \\\\\n",
    "\\text{where: } \\\\\n",
    "\\mathbf{a_u} &\\in \\mathbb{R}^{k \\times d} \\text{ - k anchor ids sampled for node}\\\\\n",
    "\\mathbf{z_u} &\\in \\mathbb{R}^{k \\times d} \\text{ - k anchor distances }\\\\\n",
    "\\mathbf{r_u} &\\in \\mathbb{R}^{m \\times d} \\text{ - m outgoing relations} \\\\\n",
    "\\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, authors sum vectors related to anchors, so that the matrix node representation is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}\n",
       "\\mathbf{hash}(u) = [\\mathbf{a_u} + \\mathbf{z_u}, \\mathbf{r_u}] = [\\mathbf{\\hat{a}_u}, \\mathbf{r}_u] \n",
       "\\in \\mathbb{R}^{(k+m) \\times d} \\tag{3}\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align*}\n",
    "\\mathbf{hash}(u) = [\\mathbf{a_u} + \\mathbf{z_u}, \\mathbf{r_u}] = [\\mathbf{\\hat{a}_u}, \\mathbf{r}_u] \n",
    "\\in \\mathbb{R}^{(k+m) \\times d} \\tag{3}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "The matrix delineated in equation (3) facilitates the transformation into a  vector for each node *u* through the application of an appropriate encoder—either an MLP (Multilayer Perceptron) or a Transformer, as explored in the original study.\n",
    "\n",
    "This encoder operates by converting the matrix into a \"flat\" vector representation for each node, thereby distilling complex relational and positional information into a condensed form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{align*}\n",
       "enc: \\mathbb{R}^{(k+m) \\times d} \\rightarrow \\mathbb{R}^{d} \\tag{4}\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "\\begin{align*}\n",
    "enc: \\mathbb{R}^{(k+m) \\times d} \\rightarrow \\mathbb{R}^{d} \\tag{4}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this encoding process with a practical example, let's consider the representation for **node 2**:\n",
    "\n",
    "1. **Anchors are assigned identifiers** starting from zero, hence `id(Anchor 1) = 0` and `id(Anchor 2) = 1`.\n",
    "2. **Relations receive identifiers similarly**, so `id(r1) = 0`, `id(r2) = 1`, and `id(r3) = 2`.\n",
    "3. **Distances are indexed in the same manner**, with ``id(dist=1) = 0`, `id(dist=2) = 1`, `id(dist=3) = 2`, etc.\n",
    "4. **With k=m=2**, two anchors and two relations are sampled for each node.\n",
    "\n",
    "Given these mappings and assuming a dimensional space d = 3, the representation according to equation (2) will look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    n1((node1)) -- r1 --- n2((node2))\n",
    "    n1 -- r2 --- n3\n",
    "    n2 -- r1 --- n3\n",
    "    n2 -- r3 --- a1(((Anchor 1)))\n",
    "    n3((node3)) -- r2 --- n4((node4))\n",
    "    n4 -- r1 --- a1\n",
    "    n4 -- r3 --- n5((node5))\n",
    "    n5 -- r2 --- a2(((Anchor 2)))\n",
    "    n2 -- r3 --- a2\n",
    "    a1 -- r1 --- a2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TB\n",
    "    a1(((Anchor 1))) --Distance=1--> ae[Anchor dist. vector]\n",
    "    a2(((Anchor 2))) --Distance=1--> ae[Anchor dist. vector]\n",
    "    r1 --> re[Relation context]\n",
    "    r3 --> re[Relation context]\n",
    "    re --Concatenate+embed--> Encoding\n",
    "    ae --Concatenate+embed--> Encoding\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}\n",
       "    & \\{a_u\\}^k = \\{0, 1 \\} \\\\\n",
       "    & \\{z_u\\}^k =\\{1, 1 \\} \\\\\n",
       "    & \\{r_j\\}^m = \\{0, 2 \\} \\\\[1em]\n",
       "    & hash(\\text{node}_2) = \\big[\\{0,1\\},  \\{1, 1 \\}^k, \\{0, 2 \\}^m\\big]\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align*}\n",
    "    & \\{a_u\\}^k = \\{0, 1 \\} \\\\\n",
    "    & \\{z_u\\}^k =\\{1, 1 \\} \\\\\n",
    "    & \\{r_j\\}^m = \\{0, 2 \\} \\\\[1em]\n",
    "    & hash(\\text{node}_2) = \\big[\\{0,1\\},  \\{1, 1 \\}^k, \\{0, 2 \\}^m\\big]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, d-dimensional embeddings are applied to each anchor, distance, and relation, mapping them to a vector of size *d*. For instance, if *d=3*, the resulting matrices for anchors, distances, and relations, aligned with equation (2), would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}\n",
       "\\mathbf{a}_u &= \\begin{bmatrix}\n",
       "    0 & 0 & 1 \\\\\n",
       "    0 & 1 & 0 \\end{bmatrix}  &\\text{ 2x3 matrix for anchors 0, 1 }\\\\[1em]\n",
       "\\mathbf{z}_u &= \\begin{bmatrix}\n",
       "    1 & 1 & 1 \\\\\n",
       "    1 & 1 & 1 \\end{bmatrix}  &\\text{ 2x3 matrix for anchor distances 1, 1 }\\\\[1em]\n",
       "\\mathbf{r}_u &= \\begin{bmatrix}\n",
       "    0 & 0 & 0 \\\\\n",
       "    2 & 2 & 2 \\end{bmatrix}  &\\text{ 2x3 matrix for outgoing relations 0, 2 }\\\\[1em]\n",
       "\\mathbf{hash}(\\text{node}_2) &= \\big[\\mathbf{a_u}, \\mathbf{z}_u,  \\mathbf{r}_u \\big] \\\\\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align*}\n",
    "\\mathbf{a}_u &= \\begin{bmatrix}\n",
    "    0 & 0 & 1 \\\\\n",
    "    0 & 1 & 0 \\end{bmatrix}  &\\text{ 2x3 matrix for anchors 0, 1 }\\\\[1em]\n",
    "\\mathbf{z}_u &= \\begin{bmatrix}\n",
    "    1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1 \\end{bmatrix}  &\\text{ 2x3 matrix for anchor distances 1, 1 }\\\\[1em]\n",
    "\\mathbf{r}_u &= \\begin{bmatrix}\n",
    "    0 & 0 & 0 \\\\\n",
    "    2 & 2 & 2 \\end{bmatrix}  &\\text{ 2x3 matrix for outgoing relations 0, 2 }\\\\[1em]\n",
    "\\mathbf{hash}(\\text{node}_2) &= \\big[\\mathbf{a_u}, \\mathbf{z}_u,  \\mathbf{r}_u \\big] \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon summing the vectors related to anchors and then concatenating them as prescribed in equation (3), we derive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}\n",
       "\\mathbf{\\hat{a}_u} = \\mathbf{a_u} + \\mathbf{z_u}, \\mathbf{r_u} &= \\begin{bmatrix}\n",
       "    1 & 1 & 2 \\\\\n",
       "    1 & 2 & 1 \\end{bmatrix}  &\\text{ 2x3 matrix for node 2 }\\\\[1em]\n",
       "\n",
       "\\mathbf{hash}(\\text{node}_2) &= \\big[\\mathbf{\\hat{a}_u}, \\mathbf{r}_u \\big] \\\\\n",
       "\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align*}\n",
    "\\mathbf{\\hat{a}_u} = \\mathbf{a_u} + \\mathbf{z_u}, \\mathbf{r_u} &= \\begin{bmatrix}\n",
    "    1 & 1 & 2 \\\\\n",
    "    1 & 2 & 1 \\end{bmatrix}  &\\text{ 2x3 matrix for node 2 }\\\\[1em]\n",
    "\n",
    "\\mathbf{hash}(\\text{node}_2) &= \\big[\\mathbf{\\hat{a}_u}, \\mathbf{r}_u \\big] \\\\\n",
    "\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step shows the encoding's ability to aggregate and simplify the complex array of anchors, distances, and relational data into a **unified, dense representation for each node**, making it readily consumable for downstream graph processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do with it?\n",
    "\n",
    "From this point now on, a user can proceed with any downstream task, like classification, clustering, etc.\n",
    "\n",
    "**The representation of each node is now a flat vector, that can be used like any other features**.\n",
    "\n",
    "It should capture unique properties of the node, like its position in the graph, its relations, etc.\n",
    "\n",
    "The paper itself mentions multiple optimizations, tricks and improvements, that can be applied to the basic NodePiece algorithm, that were skipped in this simplified description. I strongly encourage you to read the original paper, if you are interested in all the details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: The (simplified) implementation\n",
    "\n",
    "The existing implementations of the NodePiece algorithm, as provided by the original paper's authors and within the PyKeen library, are comprehensive yet complex. **These versions are optimized for performance and integration within existing frameworks, which, while beneficial for application development, may obscure the conceptual bridge between the algorithm's theoretical basis and its practical code representation. This complexity can pose challenges for those seeking to understand  the algorithm.**\n",
    "\n",
    "In light of the limited availability of implementations tailored for educational use or for those aiming to gain a more in-depth understanding of the algorithm, I have opted to develop a simplified version of NodePiece. This version is designed with clarity and extensibility in mind, offering a more accessible entry point for individuals looking to grasp the fundamental mechanics of the algorithm without the overhead of optimization and framework-specific considerations.\n",
    "\n",
    "This streamlined implementation comprises two primary components:\n",
    "\n",
    "1. **Tokenization Module**: This segment of the code is responsible for selecting anchors and relations, as well as constructing the node representations with identifiers for anchors, relations, and distances. It aligns with the processes outlined in equations (1), encapsulating the initial steps of generating a node's unique “fingerprint” through its relationship to anchors and its participation in various relations.\n",
    "2. **Models Module**: This section is tasked with embedding the identifiers into a vector space and constructing prediction models. It embodies the subsequent phase of the NodePiece algorithm, where the abstract representations of nodes are transformed into dense vector embeddings that can be utilized in downstream machine learning tasks.\n",
    "\n",
    "\n",
    "## The data\n",
    "\n",
    "For demonstration purposes, this tutorial will utilize a **small subset of the FB15k-237 dataset**. The rationale behind using a reduced version of the dataset is practicality: training a model on the full dataset locally could be prohibitively time-consuming. The subset is meticulously curated to ensure that the resultant graph remains consistent and connected, thus preserving the structural integrity and relational complexity characteristic of the full dataset. This approach allows for an expedited yet insightful exploration of the NodePiece algorithm, making it feasible to experiment with and extend the simplified implementation on a more manageable scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_subset(data: pyg_data.Data, node_count: float|int = 0.001, k_hops:int=2, relabel_nodes: bool = True, num_nodes: int = None) -> pyg_data.Data:\n",
    "    max_nodes = max(data.edge_index[0].max(), data.edge_index[1].max())\n",
    "    if type(node_count) == float:\n",
    "        node_count = int(max_nodes * node_count)\n",
    "\n",
    "    selected_nodes = random.sample(range(max_nodes), node_count)\n",
    "    subset, edge_index, mapping, edge_mask = pyg_utils.k_hop_subgraph(\n",
    "        selected_nodes,\n",
    "        edge_index=data.edge_index,\n",
    "        num_hops=k_hops,\n",
    "        relabel_nodes=relabel_nodes,\n",
    "        num_nodes=num_nodes)\n",
    "    subset_data = pyg_data.Data(\n",
    "        edge_index=edge_index,\n",
    "        edge_type=data.edge_type[edge_mask])\n",
    "    return subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'\n",
    "train_data_orig = pyg_datasets.FB15k_237(path, split='train')[0]\n",
    "val_data_orig = pyg_datasets.FB15k_237(path, split='val')[0]\n",
    "test_data_orig = pyg_datasets.FB15k_237(path, split='test')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 123816], edge_type=[123816])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg.seed_everything(123)\n",
    "\n",
    "train_sset = get_data_subset(train_data_orig, node_count=15, k_hops=2, relabel_nodes=False)\n",
    "train_sset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sset.num_edge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_is_in_train = th.isin(val_data_orig.edge_index[0], train_sset.edge_index[0]) | \\\n",
    "    th.isin(val_data_orig.edge_index[0], train_sset.edge_index[1]) | \\\n",
    "    th.isin(val_data_orig.edge_index[1], train_sset.edge_index[0]) | \\\n",
    "    th.isin(val_data_orig.edge_index[1], train_sset.edge_index[1])\n",
    "\n",
    "test_is_in_train = th.isin(test_data_orig.edge_index[0], train_sset.edge_index[0]) | \\\n",
    "    th.isin(test_data_orig.edge_index[0], train_sset.edge_index[1]) | \\\n",
    "    th.isin(test_data_orig.edge_index[1], train_sset.edge_index[0]) | \\\n",
    "    th.isin(test_data_orig.edge_index[1], train_sset.edge_index[1])\n",
    "\n",
    "val_data_related_to_train = pyg_data.Data(\n",
    "    edge_index=val_data_orig.edge_index[:, val_is_in_train],\n",
    "    edge_type=val_data_orig.edge_type[val_is_in_train])\n",
    "\n",
    "test_data_related_to_train = pyg_data.Data(\n",
    "    edge_index=test_data_orig.edge_index[:, test_is_in_train],\n",
    "    edge_type=test_data_orig.edge_type[test_is_in_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg.seed_everything(333)\n",
    "val_sset = get_data_subset(val_data_orig, node_count=8, k_hops=2, relabel_nodes=False)\n",
    "pyg.seed_everything(333)\n",
    "test_sset = get_data_subset(test_data_orig, node_count=50, k_hops=2, relabel_nodes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 402], edge_type=[402]),\n",
       " Data(edge_index=[2, 224], edge_type=[224]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sset, test_sset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset consists of the following components:\n",
    "1. Training dataset - 123'816 triplets.\n",
    "2. Valdation dataset - 402 triplets.\n",
    "3. Test dataset - 224 triplets.\n",
    "237 unique relation types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have smaller subsets of the original datasets. This will speed up computation time ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Now it is time to tokenize our graphs. We will use custom functions with simplified NodePiece logic.\n",
    "\n",
    "We will select:\n",
    "1. 30 anchors from the whole dataset.\n",
    "2. Use 20 closest anchors for each node.\n",
    "3. Use 10 relations for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreate = True\n",
    "if recreate:\n",
    "    train_features = tok.tokenize_graph(train_data_orig, n_anchors=30, k_nearest_anchors=20, m_relations=10, use_closest=True)\n",
    "    val_features = tok.tokenize_graph(val_data_orig, n_anchors=30, k_nearest_anchors=20, m_relations=10, use_closest=True)\n",
    "    test_features = tok.tokenize_graph(test_data_orig, n_anchors=30, k_nearest_anchors=20, m_relations=10, use_closest=True)\n",
    "\n",
    "    pkl.dump(train_features, open('./train_features.pkl', 'wb'))\n",
    "    pkl.dump(val_features, open('./val_features.pkl', 'wb'))\n",
    "    pkl.dump(test_features, open('./test_features.pkl', 'wb'))\n",
    "else:\n",
    "    train_features = pkl.load(open('./train_features.pkl', 'rb'))\n",
    "    val_features = pkl.load(open('./val_features.pkl', 'rb'))\n",
    "    test_features = pkl.load(open('./test_features.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_sset.to(device)\n",
    "val_data = val_sset.to(device)\n",
    "test_data = test_sset.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    train_features.anchor_hashes = train_features.anchor_hashes.long().cuda()\n",
    "    val_features.anchor_hashes = val_features.anchor_hashes.long().cuda()\n",
    "    test_features.anchor_hashes = test_features.anchor_hashes.long().cuda()\n",
    "\n",
    "    train_features.anchor_distances = train_features.anchor_distances.long().cuda()\n",
    "    val_features.anchor_distances = val_features.anchor_distances.long().cuda()\n",
    "    test_features.anchor_distances = test_features.anchor_distances.long().cuda()\n",
    "\n",
    "    train_features.rel_hashes = train_features.rel_hashes.long().cuda()\n",
    "    val_features.rel_hashes = val_features.rel_hashes.long().cuda()\n",
    "    test_features.rel_hashes = test_features.rel_hashes.long().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor selection\n",
    "\n",
    "Let's start with the anchor selection function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def degree_anchor_select(g: nx.Graph, n_anchors: int|float = 0.1) -> Tuple[List[int], Dict[int, int]]:\n",
      "    \"\"\"Anchor selection method, based on the node degree. It is based on the simplest heuristic,\n",
      "    where the nodes with the highest degree are selected as anchors - as they will most likely be connected\n",
      "    to the most nodes in the graph.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    g : nx.Graph\n",
      "        Networkx graph.\n",
      "    n_anchors : int | float, optional\n",
      "        Number of anchors to select, by default 0.1.\n",
      "        If int - the number of anchors to select.\n",
      "        If float - the fraction of the nodes to select as anchors.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    Tuple[List[int], Dict[int, int]]\n",
      "        1. List of anchor nodes.\n",
      "        2. Dictionary mapping anchor node to its id. Anchor ids are in the range [0, n_anchors).\n",
      "    \"\"\"\n",
      "    if type(n_anchors) == float:\n",
      "        n_anchors = int(g.number_of_nodes() * n_anchors)\n",
      "\n",
      "    degrees = sorted(g.degree, key=lambda x: x[1], reverse=True)\n",
      "    anchor_2_id = {}\n",
      "    anchors = []\n",
      "    for i, (node, _) in enumerate(degrees[:n_anchors]):\n",
      "        anchors.append(node)\n",
      "        anchor_2_id[node] = i\n",
      "\n",
      "    return anchors, anchor_2_id\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(tok.degree_anchor_select))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `degree_anchor_select` function exemplifies a straightforward yet effective approach to this task, leveraging the degree of nodes as a heuristic for anchor selection. **This method presumes that nodes with higher degrees, implying a larger number of connections, serve as optimal anchors due to their likelihood of being connected to a vast portion of the graph**. Here's a step-by-step breakdown of how the function operates:\n",
    "\n",
    "1. **Input Parameters**: The function accepts a NetworkX graph `g` and an `n_anchors` parameter, which dictates the number of anchors to be selected. The `n_anchors` parameter can be specified as either a float, representing the proportion of the graph's nodes to be designated as anchors (with a default of 0.1, or 10%), or an integer, indicating the exact count of anchors desired.\n",
    "2. **Degree Calculation and Sorting**: It computes the degree for each node within the graph. The nodes are then sorted based on their degree in descending order, prioritizing nodes with the highest degrees for selection as anchors.\n",
    "3. **Anchor to ID Mapping**: An `anchor_2_id` dictionary is initialized to map each selected anchor node to a unique identifier, starting from 0. This mapping facilitates the efficient identification and utilization of anchor nodes in subsequent steps of the NodePiece tokenization process.\n",
    "4. **Return Values**: The function returns a tuple comprising a list of the selected anchor nodes and the `anchor_2_id dictionary`. The list contains the nodes chosen as anchors, while the dictionary provides a mapping between these anchor nodes and their assigned IDs, enabling their direct reference in the construction of node representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building distance to K nearest anchors\n",
    "\n",
    "Next, we will build a function to calculate the shortest path distances from each node to the K nearest anchor nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def build_distance_to_k_nearest_anchors(\n",
      "        G: nx.Graph,\n",
      "        anchors: List[int],\n",
      "        anchor2id: dict,\n",
      "        k_closest_anchors: int = 15,\n",
      "        use_closest: bool = True) -> Tuple[np.ndarray, np.ndarray, int]:\n",
      "    \"\"\"For each node in the graph, calculate the distance to the k closest anchors.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    G : nx.Graph\n",
      "        Netowrkx graph.\n",
      "    anchors : List[int]\n",
      "        List of anchor nodes.\n",
      "    anchor2id : dict\n",
      "        Anchor to id mapping.\n",
      "    k_closest_anchors : int, optional\n",
      "        Number of k closest anchors to pick per node, by default 15\n",
      "    use_closest : bool, optional\n",
      "        Should closest anchors be used, or all? By default True\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    Tuple[np.ndarray, np.ndarray, int]\n",
      "        Tuple of:\n",
      "        1. Node to anchor distance matrix. Shape: (num_nodes, num_anchors).\n",
      "        2. Node to anchor id matrix. Shape: (num_nodes, num_anchors).\n",
      "        3. Maximum distance in the graph. Will be used for distance encoding/embedding.\n",
      "    \"\"\"\n",
      "    node_distances = {i: [] for i in range(G.number_of_nodes())}\n",
      "    for a in tqdm(anchors):\n",
      "        for node, dist in nx.shortest_path_length(G, source=a).items():\n",
      "            node_distances[node].append((a, dist))\n",
      "\n",
      "    node2anchor_dist = np.zeros((G.number_of_nodes(), len(anchors)))\n",
      "    node2anchor_idx = np.zeros((G.number_of_nodes(), len(anchors)))\n",
      "    unreachable_anchor_token = len(anchors)\n",
      "    node2anchor_idx.fill(unreachable_anchor_token)\n",
      "\n",
      "    max_dist = 0\n",
      "\n",
      "    for node, distances in tqdm(node_distances.items()):\n",
      "        indices_of_anchors = sorted(distances, key=lambda x: x[1])[:k_closest_anchors] if use_closest else node_distances[node]\n",
      "        for i, (anchor, dist) in enumerate(indices_of_anchors):\n",
      "            anchor_id = anchor2id[anchor]\n",
      "            node2anchor_dist[node, anchor_id] = dist\n",
      "\n",
      "            node2anchor_idx[node, i] = anchor_id\n",
      "            if dist > max_dist:\n",
      "                max_dist = dist\n",
      "    unreachable_anchor_indices = node2anchor_idx == unreachable_anchor_token\n",
      "    node2anchor_dist[unreachable_anchor_indices] = max_dist + 1\n",
      "    return node2anchor_dist, node2anchor_idx, max_dist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(tok.build_distance_to_k_nearest_anchors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps are as follows:\n",
    "\n",
    "1. **Shortest Path Calculation**: The function iterates over each anchor node, computing the shortest path distances to all other nodes within the graph. This is accomplished using NetworkX's `nx.shortest_path_length` function. The distances are collected in a dictionary node_distances, where keys represent nodes and values are the distances to each anchor. Notably, this step can be computationally intensive, particularly for larger graphs. Optimizations in implementations like PyKeen or the original NodePiece repository aim to enhance efficiency here.\n",
    "2. **Matrix initialization**: Two numpy arrays, `node2anchor_dist` and `node2anchor_idx`, are initialized to hold the distance from each node to its k closest anchors, and the indices of these anchors, respectively.An `unreachable_anchor_token` is introduced, set to the total number of anchors plus one (`A+1`), to initially populate the `node2anchor_idx` array. This serves as a placeholder for anchors that are not reachable from a given node, analogous to an \"out of vocabulary\" token in NLP.\n",
    "3. **Distance and index matrices population**: The function proceeds to sort the distances to anchors for each node, selecting the closest k anchors. The distances to and indices of these selected anchors are then stored in the respective arrays.During this process, the `max_dist` variable is updated to reflect the maximum observed distance, ensuring that any unreachable anchors are subsequently marked with a distance exceeding this maximum (`max_dist +1` - \"a magic token\").\n",
    "4. **Handle unreachable anchors**: For nodes from which an anchor is unreachable (signified by the absence of a path to the anchor), the distance is set to `max_dist + 1`. This adjustment is made by identifying indices in `node2anchor_idx` equal to the `unreachable_anchor_token` and setting the corresponding `node2anchor_dist` entries to this incremented max distance. This mechanism effectively accounts for nodes isolated from certain anchors, maintaining the integrity of the NodePiece representation by acknowledging the potential for disconnected components within the graph.\n",
    "6. **Return values**: The function concludes by returning a tuple that includes the distance matrix `node2anchor_dist`, the anchor index matrix `node2anchor_idx`, and the `max_dist` value. These outputs collectively provide a comprehensive mapping of each node's proximity to its nearest anchor points, foundational for constructing the NodePiece embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of relational context\n",
    "\n",
    "The next step is to extract the relational context for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sample_rels(pyg_g: pyg_data.Data, max_rels: int = 50) -> th.Tensor:\n",
      "    \"\"\"Samples m outgoing relations for each node. If the node has less than m relations, it pads the output with a special token.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    pyg_g : pyg_data.Data\n",
      "        PyTorch Geometric graph.\n",
      "    max_rels : int, optional\n",
      "        Maximal number of relations to use, by default 50.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    th.Tensor\n",
      "        Matrix of relations for each node. Shape: (num_nodes, max_rels).\n",
      "        Each row corresponds to specific node, each column to a relation (id).\n",
      "    \"\"\"\n",
      "    rels_matrix = []\n",
      "    missing_rel_token = pyg_g.edge_type.max() + 1\n",
      "    for node in tqdm(range(pyg_g.num_nodes)):\n",
      "        node_edges = pyg_g.edge_index[0] == node\n",
      "        node_edge_types = pyg_g.edge_type[node_edges].unique()\n",
      "        num_edge_types = len(node_edge_types)\n",
      "\n",
      "        if num_edge_types < max_rels:\n",
      "            pad = th.ones(max_rels - num_edge_types, dtype=th.long) * missing_rel_token\n",
      "            padded_edge_types = th.cat([node_edge_types, pad])\n",
      "            padded_edge_types = padded_edge_types.sort()[0]\n",
      "        else:\n",
      "            sampled_edge_types = th.randperm(num_edge_types)[:max_rels]\n",
      "            padded_edge_types = node_edge_types[sampled_edge_types].sort()[0]\n",
      "        rels_matrix.append(padded_edge_types)\n",
      "    return th.stack(rels_matrix)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(tok.sample_rels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Initialization**: The function requires a PyTorch Geometric (PyG) graph object, `pyg_g`, along with an optional `max_rels` parameter, which dictates the maximum number of relations to sample for each node. It defaults to 50. An empty list, `rels_matrix`, is prepared to hold the relational data for all nodes. Additionally, a `missing_rel_token` is defined to represent absent relations for a given node, effectively serving as an `\"out of vocabulary\"` token. This token is set to one more than the highest relation ID found in the graph.\n",
    "2. **Unique relations discovery**: For each node, it finds the unique outgoing edge types (relations).\n",
    "\n",
    "3. **Check number of relations**: For each node in the graph, the function identifies all unique outgoing relation types (edge types) connected to it.\n",
    "4. **Relation Number Adjustment** If a node's number of unique relations is less than the `max_rels` threshold, the list of relations is padded with the `missing_rel_token` to reach the specified maximum. This ensures uniformity in the relational context length across all nodes.\n",
    "Conversely, if a node is connected through more relation types than `max_rels` allows, a subset is randomly selected to conform to the limit. This random sampling is indicative of the need to balance detail with computational efficiency.\n",
    "4. **Sort and store relations**: The sampled (and potentially padded) relations for each node are sorted to maintain a consistent order. The sorted list is then appended to the `rels_matrix`, gradually building a comprehensive relational context repository for the entire graph.\n",
    "6. **Tensor conversion and return results**: Upon completion of the relational context extraction for all nodes, the `rels_matrix` list is transformed into a PyTorch tensor. This tensor, with shape (num_nodes x max_rels), systematically represents each node's relational context in a structured and machine-readable form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature matrices\n",
    "\n",
    "After all this operation we are left with three matrices:\n",
    "1. `anchor_distsances` - distances from each node to the K closest anchors. Dim: N nodes x K anchors.\n",
    "2. `anchor_hashes` - indices of the K closest anchors for each node. Dim: N nodes x K anchors.\n",
    "3. `rel_hashes` - relational context for each node. Dim: N nodes x M relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 1, 2, 1],\n",
      "        [2, 3, 2, 3, 2],\n",
      "        [1, 2, 2, 2, 2],\n",
      "        [1, 1, 2, 3, 2],\n",
      "        [2, 2, 3, 2, 2],\n",
      "        [1, 1, 2, 2, 1],\n",
      "        [1, 1, 2, 2, 2],\n",
      "        [1, 2, 2, 1, 2],\n",
      "        [2, 3, 2, 2, 2],\n",
      "        [3, 2, 3, 3, 3]], device='cuda:0')\n",
      "torch.Size([14541, 30])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.anchor_distances[:10, :5])\n",
    "print(train_features.anchor_distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4,  0,  1,  3],\n",
      "        [ 0,  2,  4,  5,  7],\n",
      "        [ 0,  5,  1,  2,  3],\n",
      "        [ 0,  1,  5,  6, 13],\n",
      "        [ 9,  0,  1,  3,  4],\n",
      "        [ 0,  1,  4,  5,  7],\n",
      "        [ 0,  1,  6, 13,  2],\n",
      "        [ 0,  3,  6, 27,  1],\n",
      "        [19, 20, 22, 28,  0],\n",
      "        [19, 20, 22, 28,  1]], device='cuda:0')\n",
      "torch.Size([14541, 30])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.anchor_hashes[:10, :5])\n",
    "print(train_features.anchor_hashes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 15,  23,  69,  72,  73],\n",
      "        [237, 237, 237, 237, 237],\n",
      "        [  1,  51, 107, 185, 201],\n",
      "        [ 17,  25,  43,  48, 232],\n",
      "        [  2, 237, 237, 237, 237],\n",
      "        [ 11,  12,  13,  25,  26],\n",
      "        [  3,   8,  17,  19,  24],\n",
      "        [  3,   6,   8,  17,  19],\n",
      "        [  4,   5,  80, 121, 237],\n",
      "        [130, 178, 237, 237, 237]], device='cuda:0')\n",
      "torch.Size([14541, 10])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.rel_hashes[:10, :5])\n",
    "print(train_features.rel_hashes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "For this exercise, we pivot towards a simpler but effective knowledge graph embedding model: TransE. While the original paper employed RotatE—a somewhat more intricate model—TransE offers a streamlined approach, focusing on the fundamental aspects of embedding relations within a graph.\n",
    "\n",
    "TransE operates by evaluating a triplet comprising a `head` node, a `relation`, and a `tail` node. **It assigns a likelihood score indicating the probability of the specified relation existing between the head and tail nodes**. The model's objective is encapsulated in the optimization of a loss function designed to distinguish true triplets from artificially generated (corrupted) ones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L}= \\sum_{(h,r,t) \\in \\mathcal{D}} \\sum_{(h',r,t') \\in \\mathcal{D}'} \\left[ \\gamma + d(h+r,t) - d(h'+r,t') \\right]_{+}\n",
    "\\tag{5}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "- $h, r, t$ is the set of true triplets\n",
    "- $h', r, t'$ is the set of corrupted triplets (negative-sampled, non-existing relations)\n",
    "- $d$ is the distance function, in case of TransE it is L1 or L2 norm.\n",
    "- $\\gamma$ is the margin parameter, responsible for separating positive and negative samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could write it in pseudocode as follows:\n",
    "\n",
    "\n",
    "```python\n",
    "for (head, relation, tail) in data:\n",
    "    head_embed = EMBED(head)\n",
    "    rel_embed = EMED(relation)\n",
    "    tail_embed = EMBED(tail)\n",
    "    score = -1 * [(head_embed + rel_embed) - tail_embed]\n",
    "    return score\n",
    "```\n",
    "\n",
    "We return `-1 x score` as we want to minimize the score, and maximize the likelihood of the triplet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interacting with NodePiece embeddings, TransE gets interesting when it comes to embedding head and tail nodes.\n",
    "\n",
    "TransE embedding in this case will perform several steps. For each head or tail node:\n",
    "1. Take its closest anchor indices and embed them.\n",
    "2. Take its distances to the closest anchors and embed them.\n",
    "3. Take its relational context and embed it.\n",
    "4. According to the equation (3): add anchor ID embedding and distance embedding, concatenate with relational embedding into a single vector.\n",
    "5. Pass this vector through the encoder (MLP or Transformer) to get the final embedding.\n",
    "\n",
    "Our implementation will look as follows - this procedure is invoked for each head and tail node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def embed_node(self, node: th.Tensor, closest_anchors, anchor_distances, rel_hash):\n",
      "\n",
      "        # Dim: (N x K) values are anchor ids --> (N x K x D)\n",
      "        anchor_embed = self.anchor_embed(closest_anchors[node])\n",
      "\n",
      "        # Dim: (N x K) values are anchor distances --> (N x K x D)\n",
      "        anchor_distances_embed = self.anchor_distances_embed(anchor_distances[node])\n",
      "\n",
      "        # Dim: (N x M) values are relation types --> (N x M x D)\n",
      "        rel_embed = self.rel_emb(rel_hash[node])\n",
      "\n",
      "        # Dim: (N x K x D)\n",
      "        combined_anchor_embed = anchor_embed + anchor_distances_embed\n",
      "\n",
      "        # N x (K + M) x D\n",
      "        stacked_embed = th.cat([combined_anchor_embed, rel_embed], dim=1)\n",
      "        N, anchors_plus_rel, hidden_channels = stacked_embed.shape\n",
      "\n",
      "        # reshape: (N x (K + M) x D) --> (N x (K + M) * D)\n",
      "        flattened_embed = stacked_embed.view(N, anchors_plus_rel * hidden_channels)\n",
      "\n",
      "        # N x (K + M) * D --> N x O\n",
      "        lin_out = self.lin_layer(flattened_embed)\n",
      "\n",
      "        return lin_out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(models.NodePieceTransE.embed_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `anchor_embed` is an embedding lookup for the anchor hashes. The weights matrix has dimensionality `((K anchors +1) x D embedding size)`. It takes `(N x K) `matrix of anchor hashes and returns `(N x K x D)` tensor.\n",
    "2. `anchor_distances_embed` is an embedding lookup for the anchor distances. The weights matrix has dimensionality `((max distance +1) x D embedding size)`. It takes `(N x K)` matrix of anchor distances and returns `(N x K x D)` tensor.\n",
    "3. `rel_embed` is an embedding lookup for the relation hashes. The weights matrix has dimensionality `((unique relations +1) x D embedding size)`. It takes `(N x M) `matrix of relation hashes and returns `(N x M x D)` tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransE model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now prepare a TransE model, wrap it in the PyTorch Lightning and train it on the FB15k-237 data subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trianing prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14445, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = max(train_data.edge_index.max(), test_data.edge_index.max(), val_data.edge_index.max())\n",
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance = max(train_features.max_distance, val_features.max_distance, test_features.max_distance) + 1\n",
    "max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = pyg_nn.kge.loader.KGTripletLoader(\n",
    "    head_index=train_data.edge_index[0],\n",
    "    rel_type=train_data.edge_type,\n",
    "    tail_index=train_data.edge_index[1],\n",
    "    batch_size=2048,\n",
    ")\n",
    "\n",
    "val_loader = pyg_nn.kge.loader.KGTripletLoader(\n",
    "    head_index=val_data.edge_index[0, :250],\n",
    "    rel_type=val_data.edge_type[:250],\n",
    "    tail_index=val_data.edge_index[1, :250],\n",
    "    batch_size=2048,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_swa = True\n",
    "swa_lr = 5e-3\n",
    "\n",
    "pyg.seed_everything(999)\n",
    "\n",
    "params = models.KGModelParams(\n",
    "    num_nodes=train_data_orig.num_nodes,\n",
    "    num_relations=train_features.n_rels+1,\n",
    "    embedding_dim=200,\n",
    "    max_distance=max_distance+1,\n",
    "    hidden_sizes=(400,),\n",
    "    num_anchors=train_features.n_anchors,\n",
    "    top_m_relations=train_features.m_relations,\n",
    "    device=device,\n",
    "    kg_model_type=models.ModelType.TransE,\n",
    "    drop_prob=0.2\n",
    ")\n",
    "model_pl = models.NodePiecePL(\n",
    "    params,\n",
    "    lr=5e-3,\n",
    "    train_features=train_features, \n",
    "    val_features=val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodePieceTransE(\n",
       "  (anchor_embed): Embedding(31, 200)\n",
       "  (anchor_distances_embed): Embedding(13, 200)\n",
       "  (lin_layer): Sequential(\n",
       "    (0): BatchNorm(8000)\n",
       "    (1): Linear(in_features=8000, out_features=400, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=400, out_features=200, bias=True)\n",
       "  )\n",
       "  (rel_emb): Embedding(238, 200)\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pl.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "th.set_float32_matmul_precision('high')\n",
    "early_stop = pl.callbacks.early_stopping.EarlyStopping(monitor='val_mean_rank', patience=3, mode='max', min_delta=0.001)\n",
    "checkpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(monitor='val_mean_rank', mode='max', save_top_k=1)\n",
    "callbacks = [early_stop, checkpoint]\n",
    "if use_swa:\n",
    "    swa = pl.callbacks.StochasticWeightAveraging(swa_lrs=swa_lr)\n",
    "    callbacks.append(swa)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=device,\n",
    "    max_epochs=100,\n",
    "    check_val_every_n_epoch=2,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=callbacks,\n",
    "    deterministic=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First - we will evaluate the model using validation set **before any training** to get the baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6f5360a84e46569c2ce063ab891881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2826664888cd472ab8ddea2ebed98172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    val_hits_at_k_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    val_mean_rank_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.000877909071277827    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   val_hits_at_k_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   val_mean_rank_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.000877909071277827   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_mean_rank_epoch': 0.000877909071277827, 'val_hits_at_k_epoch': 0.0}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodepiece_val_before_train = trainer.validate(model_pl, dataloaders=val_loader)\n",
    "nodepiece_val_before_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hits@k(10) = 0.0 and mean rank of correct tails is very very low. This is expected, as the model has not been trained yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Now let's train the model. This may take some time, depending on your system and hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NodePieceTransE | 3.4 M \n",
      "------------------------------------------\n",
      "3.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.4 M     Total params\n",
      "13.412    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9f5548c3ef40d2becd29faabdff90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516071ad659848aab8e956a0b529a091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d66d384c8a14939b2a90631156053f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125a398132f046bc9fca35372de87282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25f9a56431244a0891dec741868f965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4677933c8c764f969c38073d113f48c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f9286db45241d59a836c188ba372ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dcb40b7ffe4a65936dd415121c8174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43ed8e318f045d3a9fa45e892f17e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model_pl, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval model after training\n",
    "\n",
    "Now we can check the model performance after training. The checkpoint callback was used, so we can pick the best model across all iterations.\n",
    "\n",
    "\n",
    "We should see a significant improvement in the Hits@k and mean rank metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = trainer.checkpoint_callback.best_model_path\n",
    "\n",
    "best_model = models.NodePiecePL.load_from_checkpoint(checkpoint_path=path, model_params=params)\n",
    "\n",
    "best_model.train_features = train_features\n",
    "best_model.val_features = val_features\n",
    "best_model.test_features = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2af7768a8f4029abc200d0d1160cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f3c499ad43444a8a4efac2afd4e162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    val_hits_at_k_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3240000009536743     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    val_mean_rank_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2862264811992645     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   val_hits_at_k_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3240000009536743    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   val_mean_rank_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2862264811992645    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_mean_rank_epoch': 0.2862264811992645,\n",
       "  'val_hits_at_k_epoch': 0.3240000009536743}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodepiece_val_after_train = trainer.validate(best_model, dataloaders=val_loader)\n",
    "nodepiece_val_after_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we can see an improvement in the prediction quality. Of course, even for such a small subset of data it can take quite a long time to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you a sense of scale - the original paper used a much larger dataset, and the training took several hours on a GPU. One of the experiments (**table 10** in paper) took 7 hours with 400 epochs and 1'000 anchors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this blog post, we've taken a deep dive into the world of NodePiece, a novel approach to graph neural networks that draws inspiration from the tokenization techniques used in Transformers for natural language processing. J**ust as Transformers revolutionized text analysis by breaking down text into manageable pieces, NodePiece applies a similar concept to graphs**. It uses a set of basic elements, or \"tokens\", to represent the various parts of a graph, making it easier to handle complex networks.\n",
    "\n",
    "We started with an overview of how NodePiece borrows ideas from NLP's tokenization strategies, particularly those used in Transformers, to address the challenges of representing nodes in large and complex graphs. **This approach allows NodePiece to efficiently capture the essence of nodes and their relationships without needing to explicitly identify every single node, which is a significant advantage for tasks like link prediction, node classification, and more**.\n",
    "\n",
    "The theoretical background of NodePiece was also covered, explaining how it creates a flexible and generalized way of representing nodes by focusing on their relationships and positions within the graph. This simplifies the representation of nodes and enhances the model's ability to learn from and adapt to different graphs.\n",
    "\n",
    "Finally, we presented a simplified implementation of the NodePiece model, designed with educational purposes in mind. This implementation breaks down the concept into more understandable parts, making it easier for readers to grasp how NodePiece works and how it can be applied to real-world graph neural network tasks.\n",
    "\n",
    "Hopefully, you find it useful, and will be able to utilize NodePiece tokenization in your graph projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "1. Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. Advances in Neural Information Processing Systems, 26. https://proceedings.neurips.cc/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html\n",
    "2. Brochier, R., Guille, A., & Velcin, J. (2019). Global Vectors for Node Representations. The World Wide Web Conference, 2587–2593. https://doi.org/10.1145/3308558.3313595\n",
    "3. Church, K. W. (2017). Word2Vec. Natural Language Engineering, 23(1), 155–162.\n",
    "4. Galkin, M., Denis, E., Wu, J., & Hamilton, W. L. (2021). Nodepiece: Compositional and parameter-efficient representations of large knowledge graphs. arXiv Preprint arXiv:2106.12144.\n",
    "5. Sennrich, R., Haddow, B., & Birch, A. (2016). Neural Machine Translation of Rare Words with Subword Units (arXiv:1508.07909; Version 5). arXiv. https://doi.org/10.48550/arXiv.1508.07909\n",
    "6. Sun, Z., Deng, Z.-H., Nie, J.-Y., & Tang, J. (2019). RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space (arXiv:1902.10197; Version 1). arXiv. https://doi.org/10.48550/arXiv.1902.10197"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
